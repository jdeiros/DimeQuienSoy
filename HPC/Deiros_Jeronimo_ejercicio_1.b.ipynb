{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deiros_Jeronimo_ejercicio_1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN4stAnEYTsWwMIMY7qCuFG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdeiros/soa-2020/blob/master/HPC/Deiros_Jeronimo_ejercicio_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktOqK1RQusis"
      },
      "source": [
        "#1. Introducción\n",
        "El siguiente cuaderno realiza la suma de dos vectores en forma secuencial, utilizando el procesador CPU. El algoritmo se basa en la función **axpy** [3] de nivel 1, de la biblioteca BLAS [4] que resuelve la ecuación:\n",
        "\n",
        "Su objetivo es enseñar a los alumnos como se utiliza Python[2] la plataforma Colab [1] y la programación secuencial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qty_DG4vCSb"
      },
      "source": [
        "#2. Armado de ambiente\n",
        "\n",
        "Instala en el cuaderno el módulo CUDA de Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWe4zsmvFrp",
        "outputId": "93ccbafb-5a41-487d-d1fc-73cc7f3dc39c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycuda\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/61/47d3235a4c13eec5a5f03594ddb268f4858734e02980afbcd806e6242fa5/pycuda-2020.1.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 14.4MB/s \n",
            "\u001b[?25hCollecting pytools>=2011.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/30/c9362a282ef89106768cba9d884f4b2e4f5dc6881d0c19b478d2a710b82b/pytools-2020.4.3.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.4.2)\n",
            "Collecting appdirs>=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
            "Collecting mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.18.5)\n",
            "Requirement already satisfied: dataclasses>=0.7 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (0.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.1)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2020.1-cp36-cp36m-linux_x86_64.whl size=621010 sha256=c968a10f3080510ee4b49020d6d2775492177b44eed869839ccb74c20fd9107f\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/78/d1/5bb826f81d9d490297a348d818ff3ee6dd6f2075b06dde6ea0\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2020.4.3-py2.py3-none-any.whl size=61374 sha256=a488485e0b410bff3adfab186d139248194b8e7213289e4395dacdbea8253372\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/c7/81/a22edb90b0b09a880468b2253bb1df8e9f503337ee15432c64\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: appdirs, pytools, mako, pycuda\n",
            "Successfully installed appdirs-1.4.4 mako-1.1.3 pycuda-2020.1 pytools-2020.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEFXCm7UvQmc"
      },
      "source": [
        "#3. Desarrollo\n",
        "\n",
        "Ejecuta el Código CPU - GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVHj_eMNvTKl",
        "outputId": "0e4ccc22-f3eb-4610-db57-7cabecbef90d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title 3.1 Parámetros de ejecución { vertical-output: true }\n",
        "\n",
        "cantidad_N =   500#@param {type: \"number\"}\n",
        "alfa =   1#@param {type: \"number\"}\n",
        "# --------------------------------------------\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "tiempo_total = datetime.now()\n",
        "\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "import numpy\n",
        "\n",
        "# --------------------------------------------\n",
        "# Definición de función que transforma el tiempo en  milisegundos \n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "\n",
        "\n",
        "# CPU - Defino la memoria de los vectores en cpu.\n",
        "x_cpu = numpy.random.randn( cantidad_N )\n",
        "x_cpu = x_cpu.astype( numpy.float32() )\n",
        "\n",
        "y_cpu = numpy.random.randn( cantidad_N )\n",
        "y_cpu = y_cpu.astype( numpy.float32() )\n",
        "\n",
        "#tiempo_ini_cpu = datetime.now()\n",
        "\n",
        "r_cpu = numpy.empty_like( x_cpu )\n",
        "\n",
        "# CPU - reservo la memoria GPU.\n",
        "x_gpu = cuda.mem_alloc( x_cpu.nbytes )\n",
        "y_gpu = cuda.mem_alloc( y_cpu.nbytes )\n",
        "\n",
        "# GPU - Copio la memoria al GPU.\n",
        "cuda.memcpy_htod( x_gpu, x_cpu )\n",
        "cuda.memcpy_htod( y_gpu, y_cpu )\n",
        "\n",
        "# CPU - Defino la función kernel que ejecutará en GPU.\n",
        "module = SourceModule(\"\"\"\n",
        "__global__ void kernel_axpy( int n, float alfa, float *X, float *Y )\n",
        "{\n",
        "  int idx = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "  if( idx < n )\n",
        "  {\n",
        "    Y[idx]  = alfa*X[idx] + Y[idx];\n",
        "  }\n",
        "}\n",
        "\"\"\") \n",
        "# CPU - Genero la función kernel.\n",
        "kernel = module.get_function(\"kernel_axpy\")\n",
        "\n",
        "tiempo_gpu = datetime.now()\n",
        "\n",
        "# GPU - Ejecuta el kernel.\n",
        "# TODO: Falta consultar limites del GPU, para armar las dimensiones correctamente.\n",
        "dim_hilo = 256\n",
        "dim_bloque = numpy.int( (cantidad_N+dim_hilo-1) / dim_hilo )\n",
        "print( \"Thread x: \", dim_hilo, \", Bloque x:\", dim_bloque )\n",
        "\n",
        "#TODO: Ojo, con los tipos de las variables en el kernel.\n",
        "kernel( numpy.int32(cantidad_N),numpy.float32(alfa), x_gpu, y_gpu, block=( dim_hilo, 1, 1 ),grid=(dim_bloque, 1,1) )\n",
        "\n",
        "tiempo_gpu = datetime.now() - tiempo_gpu\n",
        "\n",
        "# GPU - Copio el resultado desde la memoria GPU.\n",
        "cuda.memcpy_dtoh( r_cpu, y_gpu )\n",
        "\n",
        "\"\"\"\n",
        "# CPU - Informo el resutlado.\n",
        "print( \"------------------------------------\")\n",
        "print( \"X: \" )\n",
        "print( x_cpu )\n",
        "print( \"------------------------------------\")\n",
        "print( \"Y: \" )\n",
        "print( y_cpu )\n",
        "print( \"------------------------------------\")\n",
        "print( \"R: \" )\n",
        "print( r_cpu )\n",
        "\"\"\"\n",
        "\n",
        "tiempo_total = datetime.now() - tiempo_total\n",
        "\n",
        "print( \"Cantidad de elementos: \", cantidad_N )\n",
        "print( \"Thread x: \", dim_hilo, \", Bloque x:\", dim_bloque )\n",
        "print(\"Tiempo CPU: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n",
        "print(\"Tiempo GPU: \", tiempo_en_ms( tiempo_gpu   ), \"[ms]\" )"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thread x:  256 , Bloque x: 2\n",
            "Cantidad de elementos:  500\n",
            "Thread x:  256 , Bloque x: 2\n",
            "Tiempo CPU:  1138.983 [ms]\n",
            "Tiempo GPU:  2.277 [ms]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sChMbfn8vgG1"
      },
      "source": [
        "#4. Tabla de pasos\n",
        "\n",
        "Procesador | Funcion | Detalle\n",
        "------------ | ------------- | -------------\n",
        "CPU | @param | Lectura del tamaño de vectories de Colab.\n",
        "CPU | import | Importa los módulos para funcionar.\n",
        "CPU | datetime.now() | Toma el tiempo actual.\n",
        "CPU | numpy.random.randn( Cantidad_N ) | Inicializa los vectores A, B y R.\n",
        "**GPU** | cuda.mem_alloc() | Reserva la memoria en GPU.\n",
        "**GPU** | cuda.memcpy_htod() | Copia las memorias desde el CPU al GPU.\n",
        "CPU | SourceModule() | Define el código del Kernel\n",
        "CPU | module.get_function() | Genera la función del Kernel GPU.\n",
        "CPU | dim_tx/dim_bx | Calcula las dimensiones.\n",
        "**GPU** |kernel() | Ejecuta el kernel en GPU\n",
        "CPU | cuda.memcpy_dtoh() | Copia el resultado desde GPU memoria A a CPU memoria R.\n",
        "CPU | print() | Informo los resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VX-0yKX0vnTY"
      },
      "source": [
        "#5. Conclusiones\n",
        "\n",
        "Las conclusiones son explicadas en clase...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNOtiJKMvvxm"
      },
      "source": [
        "#6. Bibliografía\n",
        "\n",
        "[1] MARKDOWN SYNTAX Colab: PDF\n",
        "\n",
        "[2] Introducción a Python: Página Colab\n",
        "\n",
        "[3] Función Axpy de biblioteca BLAS: Referencia\n",
        "\n",
        "[4] Biblioteca BLAS: Referencia\n",
        "\n",
        "[5] Documentación PyCUDA: WEB\n",
        "\n",
        "[6] Repositorio de PyCUDA: WEB"
      ]
    }
  ]
}